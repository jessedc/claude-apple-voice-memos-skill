#!/usr/bin/env python3
# SPDX-License-Identifier: 0BSD
# Copyright (c) 2025 Tomoki Aonuma
# Source: https://github.com/uasi/extract-apple-voice-memos-transcript

import argparse
import json
import os
import re
import struct
import sys

VOICE_MEMOS_PATH = "~/Library/Group Containers/group.com.apple.VoiceMemos.shared/Recordings/"


def resolve_file_path(filename):
    """Resolve file path, auto-detecting recordings directory if needed."""
    # If it's an absolute path or exists as-is, use it directly
    if os.path.isabs(filename) or os.path.exists(filename):
        return filename

    # Try prepending the recordings directory
    recordings_dir = os.path.expanduser(VOICE_MEMOS_PATH)
    full_path = os.path.join(recordings_dir, filename)
    if os.path.exists(full_path):
        return full_path

    # Return original - will fail with clear file-not-found error
    return filename


def read_atom_header(f):
    header = f.read(8)
    if len(header) < 8:
        return None, None, 0

    size = struct.unpack(">I", header[:4])[0]
    atom_type = header[4:8].decode("ascii", errors="ignore")

    if size == 1:
        extended_size = struct.unpack(">Q", f.read(8))[0]
        return atom_type, extended_size, 16

    return atom_type, size, 8


def find_atom(f, end_pos, target_type):
    while f.tell() < end_pos:
        current_pos = f.tell()
        atom_type, atom_size, header_size = read_atom_header(f)

        if atom_type is None or atom_size == 0:
            break

        atom_end = current_pos + atom_size

        if atom_type == target_type:
            return atom_end, header_size
        else:
            f.seek(atom_end)

    return None, None


def error_exit(message):
    print(message, file=sys.stderr)
    sys.exit(1)


def format_timestamp(seconds):
    """Format seconds into [H:MM:SS] or [M:SS] format."""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    
    if hours > 0:
        return f"[{hours}:{minutes:02d}:{secs:02d}]"
    else:
        return f"[{minutes}:{secs:02d}]"


def should_break_line(current_text, next_text, time_gap, word_count):
    """Determine if a line break should occur based on multiple factors.

    Priority order (matching industry best practices):
    1. Sentence-ending punctuation (.!?) is the primary break signal
    2. Large time gaps (>= 4s) indicate paragraph-level pauses
    3. Moderate gaps (>= 2s) with sufficient words break at natural points
    4. Force break at max word count to prevent runaway lines
    """
    # Configuration constants
    MIN_GAP_FOR_BREAK = 2.0  # seconds - moderate pause
    PARAGRAPH_GAP = 4.0      # seconds - definitely break (topic shift)
    TARGET_WORDS = 12        # aim for this many words per line
    MAX_WORDS = 25           # force break if line gets this long
    MIN_WORDS_SENTENCE = 4   # minimum for sentence-ending break
    MIN_WORDS_PARAGRAPH = 6  # minimum for paragraph break (prevents short fragments)

    # Check if text ends with pause marker (ellipsis) - don't break on these
    if current_text and current_text.rstrip().endswith('...'):
        return False

    # Primary signal: sentence-ending punctuation
    # Always break after .!? as long as we have a minimal sentence
    if current_text and current_text.rstrip().endswith(('.', '!', '?')):
        if word_count >= MIN_WORDS_SENTENCE:
            return True

    # Large gap (paragraph-level pause) - require more words to prevent fragments
    if time_gap >= PARAGRAPH_GAP and word_count >= MIN_WORDS_PARAGRAPH:
        return True

    # Moderate gap with enough words - break at natural points
    if time_gap >= MIN_GAP_FOR_BREAK and word_count >= TARGET_WORDS:
        # Break at commas, semicolons, colons
        if current_text and current_text.rstrip().endswith((',', ';', ':')):
            return True

        # Break after conjunctions
        conjunctions = ['and', 'but', 'so', 'because', 'when', 'if', 'that', 'which']
        last_word = current_text.rstrip().split()[-1].lower().rstrip('.,;:') if current_text else ''
        if last_word in conjunctions:
            return True

    # Force break if line is too long (safety net)
    if word_count >= MAX_WORDS:
        return True

    return False


def clean_pause_markers(text):
    """Remove Apple's pause/hesitation markers (ellipsis patterns)."""
    # Remove ". .." and ". .. .." patterns that result from joining segments
    text = re.sub(r'\.\s*\.\s*\.+', '', text)

    # Remove standalone "..." or ". ." patterns
    text = re.sub(r'(?<!\w)\.{2,}', '', text)

    # Remove trailing "..." from words (e.g., "dialogue..." -> "dialogue")
    text = re.sub(r'\.{3}\s*', ' ', text)

    # Clean up resulting double/multiple spaces
    text = ' '.join(text.split())

    return text


def clean_disfluencies(text):
    """Clean up common speech disfluencies while preserving meaning."""
    # First clean pause markers
    text = clean_pause_markers(text)

    # Remove extra spaces and normalize
    text = ' '.join(text.split())

    # Handle false starts: "I travelled to I travelled to Asia" -> "I travelled to Asia"
    # Match 2-5 word phrases that repeat (with or without punctuation/ellipsis between)
    # Pattern: phrase, optional punctuation/space, same phrase again
    for phrase_len in range(5, 1, -1):  # Try longer phrases first
        pattern = r'\b((?:\w+\s+){' + str(phrase_len - 1) + r'}\w+)\s*[.,]*\s*\1\b'
        text = re.sub(pattern, r'\1', text, flags=re.IGNORECASE)

    # Handle "word, word" repetitions (e.g., "I'm, I'm" -> "I'm")
    pattern = r"\b(\w+['']?\w*),\s+\1\b"
    text = re.sub(pattern, r'\1', text, flags=re.IGNORECASE)

    # Handle "I I" or "the the" type repetitions
    pattern = r'\b(\w+)\s+\1\b'
    text = re.sub(pattern, r'\1', text, flags=re.IGNORECASE)

    # Remove filler words (uh, um)
    text = re.sub(r'\b[Uu]h\.{0,3}\s*', '', text)
    text = re.sub(r'\b[Uu]m\.{0,3}\s*', '', text)
    text = re.sub(r',\s*[Uu]h\s*,', ',', text)  # Handle ", uh," patterns
    text = re.sub(r',\s*[Uu]m\s*,', ',', text)

    # Clean up spacing around punctuation
    text = re.sub(r'\s+([.,;:!?])', r'\1', text)  # Remove space before punctuation
    text = re.sub(r'([.,;:!?])([^\s])', r'\1 \2', text)  # Add space after punctuation if missing

    # Remove trailing commas that indicate interruptions
    text = re.sub(r',\s*$', '', text)

    # Final cleanup of extra spaces
    text = ' '.join(text.split())

    return text.strip()


def extract_text_with_timestamps(json_obj):
    """Extract text segments with their timestamps from the JSON object."""
    # Paragraph break threshold (seconds between lines to insert blank line)
    PARAGRAPH_GAP_THRESHOLD = 6.0

    segments = []

    # Check if we have attributedString
    attributed_string = json_obj.get("attributedString")

    if isinstance(attributed_string, list):
        # Interleaved format: text and time attributes mixed in array
        current_time = 0
        for i, item in enumerate(attributed_string):
            if isinstance(item, str):
                # Look for the next item which might contain timeRange
                time_info = None
                if i + 1 < len(attributed_string) and isinstance(attributed_string[i + 1], dict):
                    time_range = attributed_string[i + 1].get("timeRange")
                    if time_range and isinstance(time_range, list) and len(time_range) >= 1:
                        current_time = time_range[0]
                        time_info = current_time

                if time_info is not None:
                    segments.append((time_info, item))
                elif segments:  # Use the last known time if no new time info
                    segments.append((current_time, item))
                else:
                    segments.append((0, item))

    elif isinstance(attributed_string, dict):
        # Separated format: attributeTable contains time ranges, runs contains text
        runs = attributed_string.get("runs", [])
        attribute_table = attributed_string.get("attributeTable", [])

        current_time = 0
        for i in range(0, len(runs), 2):
            if i < len(runs):
                text = runs[i] if isinstance(runs[i], str) else ""

                # Get attribute index if available
                if i + 1 < len(runs) and isinstance(runs[i + 1], int):
                    attr_index = runs[i + 1]
                    # attributeTable is a list, use index directly
                    if isinstance(attribute_table, list) and 0 <= attr_index < len(attribute_table):
                        time_range = attribute_table[attr_index].get("timeRange")
                        if time_range and isinstance(time_range, list) and len(time_range) >= 1:
                            current_time = time_range[0]

                segments.append((current_time, text))

    if not segments:
        return ""

    # Group segments into lines with improved logic
    lines = []
    current_line_time = segments[0][0]
    current_line_text = []
    prev_segment_time = segments[0][0]

    for time, text in segments:
        if text.strip():
            # Calculate gap from previous segment (not from line start)
            time_gap = time - prev_segment_time

            # Count words in current line
            current_words = ' '.join(current_line_text).split()
            word_count = len(current_words)

            # Determine if we should break the line
            if current_line_text and should_break_line(
                ' '.join(current_line_text),
                text,
                time_gap,
                word_count
            ):
                # Clean and add the completed line
                line_text = ' '.join(current_line_text)
                line_text = clean_disfluencies(line_text)
                if line_text.strip():
                    lines.append((current_line_time, line_text))
                current_line_time = time
                current_line_text = [text]
            else:
                current_line_text.append(text)

            prev_segment_time = time

    # Add the last line
    if current_line_text:
        line_text = ' '.join(current_line_text)
        line_text = clean_disfluencies(line_text)
        if line_text.strip():
            lines.append((current_line_time, line_text))

    # Format and combine lines with paragraph breaks
    result = []
    prev_line_time = None

    for time, text in lines:
        text = text.strip()
        if text:
            # Insert paragraph break if there's a large time gap between lines
            if prev_line_time is not None and (time - prev_line_time) >= PARAGRAPH_GAP_THRESHOLD:
                result.append("")  # Blank line for paragraph break

            timestamp = format_timestamp(time)
            result.append(f"{timestamp} {text}")
            prev_line_time = time

    return "\n".join(result)


def process_m4a_file(filename, mode):
    with open(filename, "rb") as f:
        file_size = f.seek(0, 2)
        f.seek(0)

        moov_end, _ = find_atom(f, file_size, "moov")
        if not moov_end:
            error_exit("error: 'moov' atom not found")

        trak_end, _ = find_atom(f, moov_end, "trak")
        if not trak_end:
            error_exit("error: 'trak' atom not found")

        udta_end, _ = find_atom(f, trak_end, "udta")
        if not udta_end:
            error_exit("error: 'udta' atom not found")

        tsrp_end, header_size = find_atom(f, udta_end, "tsrp")
        if not tsrp_end:
            error_exit("error: 'tsrp' atom not found")

        current_pos = f.tell()
        data_size = tsrp_end - current_pos
        tsrp_data = f.read(data_size)

        if mode == "raw":
            sys.stdout.buffer.write(tsrp_data)
            return

        json_obj = {}
        try:
            json_obj = json.loads(tsrp_data.decode("utf-8"))
        except Exception:
            error_exit("error: could not parse transcript data")

        if mode == "json":
            json.dump(json_obj, sys.stdout, ensure_ascii=False, separators=(",", ":"))
            print()
            return

        if mode == "timestamps":
            result = extract_text_with_timestamps(json_obj)
            if result:
                print(result)
            return

        printed = False
        attributedString = json_obj.get("attributedString")
        if isinstance(attributedString, list):
            for item in attributedString:
                if isinstance(item, str):
                    print(item, end="")
                    printed = True
        elif isinstance(attributedString, dict):
            for item in attributedString.get("runs", []):
                if isinstance(item, str):
                    print(item, end="")
                    printed = True
        if printed:
            print()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Extract transcript data from Apple Voice Memos .m4a files."
    )
    parser.add_argument("filename", help="path to the .m4a file")
    group = parser.add_mutually_exclusive_group()
    group.add_argument(
        "--text", action="store_true", help="print transcript as plain text (without timestamps)"
    )
    group.add_argument(
        "--json", action="store_true", help="print transcript data as JSON"
    )
    group.add_argument("--raw", action="store_true", help="print raw transcript data")
    args = parser.parse_args()

    if args.json:
        mode = "json"
    elif args.raw:
        mode = "raw"
    elif args.text:
        mode = "text"
    else:
        mode = "timestamps"  # Default to timestamps

    filepath = resolve_file_path(args.filename)
    process_m4a_file(filepath, mode=mode)
